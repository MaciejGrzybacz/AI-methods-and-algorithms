# Lab 6. Reinforcement Learning via Q-Learning

## TODO:

Fill missing code according to the `TODO:` comments in the following files:
- [x] `src/algorithms/q_learning/qlearning.py`
- [x] run `01_experiment_greedy.py`
- [ ] `src/algorithms/q_learning/double_q.py`
- [ ] run `02_experiment_optimistic.py`
- [ ] `src/algorithms/q_learning/dynaq.py`
- [ ] run `03_experiment_deterministic.py`
- [ ] `src/algorithms/q_learning/dynaq_plus.py`
- [ ] run `04_experiment_dynamic.py`

The experiments are described in the files headers.

## Sources

[The famous introduction](https://www.andrew.cmu.edu/course/10-703/textbook/BartoSutton.pdf) is a recommended reading for the RL novices. 
In this case, sections 6.5, 6.7, 8.2 and 8.3 correspond to the algorithms presented in this class.

## Grading

* [x] Make sure, you have a **private** group
  * [how to create a group](https://docs.gitlab.com/ee/user/group/#create-a-group)
* [x] Fork this project into your private group
  * [how to create a fork](https://docs.gitlab.com/ee/user/project/repository/forking_workflow.html#creating-a-fork)
* [x] Add @bobot-is-a-bot as the new project's member (role: **maintainer**)
  * [how to add an user](https://docs.gitlab.com/ee/user/project/members/index.html#add-a-user)

## How To Submit Solutions

* [ ] Clone repository: git clone:
    ```bash
    git clone <repository url>
    ```
* [ ] Solve the exercises
* [ ] Commit your changes
    ```bash
    git add <path to the changed files>
    git commit -m <commit message>
    ```
* [ ] Push changes to the gitlab master branch
    ```bash
    git push -u origin master
    ```

The rest will be taken care of automatically. You can check the `GRADE.md` file for your grade / test results. 
Be aware that it may take some time (up to one hour) till this file


